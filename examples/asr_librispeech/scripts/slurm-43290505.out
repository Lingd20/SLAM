/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
Error executing job with overrides: ['++train_config.enable_fsdp=false', '++train_config.enable_ddp=true', '++train_config.use_fp16=true', '++model_config.llm_name=TinyLlama-1.1B-Chat-v1.0', '++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', '++model_config.llm_dim=2048', '++model_config.encoder_name=whisper', '++model_config.encoder_projector_ds_rate=5', '++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/Whisper/large-v3.pt', '++model_config.encoder_dim=1280', '++model_config.encoder_projector=linear', '++dataset_config.dataset=speech_dataset', '++dataset_config.train_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/data/M03_train.jsonl', '++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/data/M03_validation.jsonl', '++dataset_config.input_type=mel', '++dataset_config.mel_size=128', '++train_config.model_name=asr', '++train_config.num_epochs=3', '++train_config.freeze_encoder=true', '++train_config.freeze_llm=true', '++train_config.batching_strategy=custom', '++train_config.warmup_steps=1000', '++train_config.total_steps=100000', '++train_config.lr=1e-4', '++train_config.validation_interval=1000', '++train_config.batch_size_training=2', '++train_config.val_batch_size=2', '++train_config.num_workers_dataloader=2', '++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/TinyLlama-1.1B-Chat-v1.0-librispeech-linear-steplrwarmupkeep1e-4-whisper-largev3-20240714/M03', '++metric=acc']
Traceback (most recent call last):
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/finetune_asr.py", line 45, in main_hydra
    train(kwargs)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/pipeline/finetune.py", line 127, in main
    setup()
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/train_utils.py", line 472, in setup
    torch.cuda.set_device(rank)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/cuda/__init__.py", line 399, in set_device
    torch._C._cuda_setDevice(device)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
E0714 18:43:14.941000 47016674465984 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 20497) of binary: /work/van-speech-nlp/jindaznb/slamenv/bin/python
Traceback (most recent call last):
  File "/work/van-speech-nlp/jindaznb/slamenv/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py", line 879, in main
    run(args)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/asr_librispeech/finetune_asr.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-14_18:43:14
  host      : c0237.discovery.neu.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 20497)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
