{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07f6c69-b94f-4b8f-b8fa-bddb5f7a2a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.17\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcd207-6202-4ba8-96a4-e3988eba77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea94885-44a4-4df6-b39d-bba8c18f329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c33c48-af4e-4519-889c-60fa979c71bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading \u001b[1manaconda3/2022.05\u001b[22m\u001b[m\n",
      "  \u001b[91mERROR\u001b[0m: Module cannot be loaded due to a conflict.\u001b[m\n",
      "    HINT: Might try \"module unload anaconda3\" first.\u001b[m\n",
      "\u001b[K\u001b[?1l\u001b>/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/inference_asr_batch.py\", line 1, in <module>\n",
      "    from slam_llm.pipeline.inference_batch import main as inference\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/pipeline/inference_batch.py\", line 6, in <module>\n",
      "    from slam_llm.models.slam_model import slam_model\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/models/slam_model.py\", line 10, in <module>\n",
      "    from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/__init__.py\", line 22, in <module>\n",
      "    from .auto import (\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/auto.py\", line 31, in <module>\n",
      "    from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/mapping.py\", line 23, in <module>\n",
      "    from .peft_model import (\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/peft_model.py\", line 38, in <module>\n",
      "    from .tuners import (\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/tuners/__init__.py\", line 21, in <module>\n",
      "    from .lora import LoraConfig, LoraModel\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/tuners/lora/__init__.py\", line 21, in <module>\n",
      "    from .model import LoraModel\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/peft/src/peft/tuners/lora/model.py\", line 45, in <module>\n",
      "    import bitsandbytes as bnb\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/bitsandbytes/__init__.py\", line 16, in <module>\n",
      "    from .nn import modules\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/bitsandbytes/nn/__init__.py\", line 6, in <module>\n",
      "    from .triton_based_modules import SwitchBackLinear, SwitchBackLinearGlobal, SwitchBackLinearVectorwise, StandardLinear\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/bitsandbytes/nn/triton_based_modules.py\", line 8, in <module>\n",
      "    from bitsandbytes.triton.dequantize_rowwise import dequantize_rowwise\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/bitsandbytes/triton/dequantize_rowwise.py\", line 10, in <module>\n",
      "    import triton\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/__init__.py\", line 8, in <module>\n",
      "    from .runtime import (\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/runtime/__init__.py\", line 1, in <module>\n",
      "    from .autotuner import (Autotuner, Config, Heuristics, OutOfResources, autotune, heuristics)\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/runtime/autotuner.py\", line 7, in <module>\n",
      "    from ..testing import do_bench\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/testing.py\", line 8, in <module>\n",
      "    from . import language as tl\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/language/__init__.py\", line 4, in <module>\n",
      "    from . import math\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/language/math.py\", line 4, in <module>\n",
      "    from ..common.build import is_hip\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/common/__init__.py\", line 1, in <module>\n",
      "    from .build import _build, cuda_include_dir, libcuda_dirs\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/triton/common/build.py\", line 10, in <module>\n",
      "    import setuptools\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/setuptools/__init__.py\", line 8, in <module>\n",
      "    import _distutils_hack.override  # noqa: F401\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/_distutils_hack/override.py\", line 1, in <module>\n",
      "    __import__('_distutils_hack').do_override()\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/_distutils_hack/__init__.py\", line 70, in do_override\n",
      "    ensure_local_distutils()\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/_distutils_hack/__init__.py\", line 56, in ensure_local_distutils\n",
      "    core = importlib.import_module('distutils.core')\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 13, in <module>\n",
      "    from .cmd import Command\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 12, in <module>\n",
      "    from . import _modified, archive_util, dir_util, file_util, util\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/setuptools/_distutils/_modified.py\", line 8, in <module>\n",
      "    from .py39compat import zip_strict\n",
      "ModuleNotFoundError: No module named 'distutils.py39compat'\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/decode_wavlm_large_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3803a-fc2b-4645-a844-00fa6844e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash scripts/decode_hubert_xtralarge_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1710e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  8 23:19:54 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   50C    P0              62W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/finetune_asr.py\", line 1, in <module>\n",
      "    from slam_llm.pipeline.finetune import main as train\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/pipeline/finetune.py\", line 23, in <module>\n",
      "    from slam_llm.utils import fsdp_auto_wrap_policy\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/__init__.py\", line 7, in <module>\n",
      "    from slam_llm.utils.train_utils import *\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/train_utils.py\", line 34, in <module>\n",
      "    import wandb\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/__init__.py\", line 27, in <module>\n",
      "    from wandb import sdk as wandb_sdk\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/__init__.py\", line 25, in <module>\n",
      "    from .artifacts.artifact import Artifact\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/artifacts/artifact.py\", line 46, in <module>\n",
      "    from wandb.apis.normalize import normalize_exceptions\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/__init__.py\", line 44, in <module>\n",
      "    from .public import Api as PublicApi  # noqa\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/public/__init__.py\", line 1, in <module>\n",
      "    from wandb.apis.public.api import Api, RetryingClient, requests\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/public/api.py\", line 31, in <module>\n",
      "    from wandb.sdk.launch.utils import LAUNCH_DEFAULT_PROJECT\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/__init__.py\", line 1, in <module>\n",
      "    from ._launch import launch\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/_launch.py\", line 12, in <module>\n",
      "    from . import loader\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/loader.py\", line 7, in <module>\n",
      "    from wandb.docker import is_docker_installed\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/docker/__init__.py\", line 8, in <module>\n",
      "    from dockerpycreds.utils import find_executable  # type: ignore\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/__init__.py\", line 2, in <module>\n",
      "    from .store import Store\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/store.py\", line 9, in <module>\n",
      "    from .utils import create_environment_dict\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/utils.py\", line 1, in <module>\n",
      "    import distutils.spawn\n",
      "ModuleNotFoundError: No module named 'distutils.spawn'\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/finetune_asr.py\", line 1, in <module>\n",
      "    from slam_llm.pipeline.finetune import main as train\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/pipeline/finetune.py\", line 23, in <module>\n",
      "    from slam_llm.utils import fsdp_auto_wrap_policy\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/__init__.py\", line 7, in <module>\n",
      "    from slam_llm.utils.train_utils import *\n",
      "  File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/train_utils.py\", line 34, in <module>\n",
      "    import wandb\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/__init__.py\", line 27, in <module>\n",
      "    from wandb import sdk as wandb_sdk\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/__init__.py\", line 25, in <module>\n",
      "    from .artifacts.artifact import Artifact\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/artifacts/artifact.py\", line 46, in <module>\n",
      "    from wandb.apis.normalize import normalize_exceptions\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/__init__.py\", line 44, in <module>\n",
      "    from .public import Api as PublicApi  # noqa\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/public/__init__.py\", line 1, in <module>\n",
      "    from wandb.apis.public.api import Api, RetryingClient, requests\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/apis/public/api.py\", line 31, in <module>\n",
      "    from wandb.sdk.launch.utils import LAUNCH_DEFAULT_PROJECT\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/__init__.py\", line 1, in <module>\n",
      "    from ._launch import launch\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/_launch.py\", line 12, in <module>\n",
      "    from . import loader\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/sdk/launch/loader.py\", line 7, in <module>\n",
      "    from wandb.docker import is_docker_installed\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/wandb/docker/__init__.py\", line 8, in <module>\n",
      "    from dockerpycreds.utils import find_executable  # type: ignore\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/__init__.py\", line 2, in <module>\n",
      "    from .store import Store\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/store.py\", line 9, in <module>\n",
      "    from .utils import create_environment_dict\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/dockerpycreds/utils.py\", line 1, in <module>\n",
      "    import distutils.spawn\n",
      "ModuleNotFoundError: No module named 'distutils.spawn'\n",
      "E0708 23:20:12.422979 47152658749248 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 94376) of binary: /work/van-speech-nlp/jindaznb/mmenv/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/distributed/run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/distributed/run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 263, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "examples/asr_librispeech/finetune_asr.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-07-08_23:20:12\n",
      "  host      : d1004.discovery.neu.edu\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 94377)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-07-08_23:20:12\n",
      "  host      : d1004.discovery.neu.edu\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 94376)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/finetune_wavlm_large_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891aa96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.42.0\n",
      "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in /work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages (from scipy->bitsandbytes==0.42.0) (1.26.4)\n",
      "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.43.2.dev0\n",
      "    Uninstalling bitsandbytes-0.43.2.dev0:\n",
      "      Successfully uninstalled bitsandbytes-0.43.2.dev0\n",
      "Successfully installed bitsandbytes-0.42.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a9529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==69.5.1\n",
      "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 70.1.0\n",
      "    Uninstalling setuptools-70.1.0:\n",
      "      Successfully uninstalled setuptools-70.1.0\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd46e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -etuptools (/work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mName: setuptools\n",
      "Version: 70.1.1\n",
      "Summary: Easily download, build, install, upgrade, and uninstall Python packages\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Python Packaging Authority <distutils-sig@python.org>\n",
      "License: \n",
      "Location: /work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: lightning-utilities, marisa-trie, nemo_text_processing, Scrapy, sip, spacy, spyder, tensorboard, thinc, wandb, zope.interface\n"
     ]
    }
   ],
   "source": [
    "!pip show setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c7d6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: *** No rule to make target 'cuda11x_nomatmul'.  Stop.\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VERSION=118 make cuda11x_nomatmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6da603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: slam-llm\n",
      "Version: 0.0.1\n",
      "Summary: SLAM-LLM is a deep learning toolkit that allows researchers and developers to train custom multimodal large language model (MLLM), focusing on Speech, Language, Audio, Music processing. We provide detailed recipes for training and high-performance checkpoints for inference.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: /work/van-speech-nlp/jindaznb/mmenv/lib/python3.9/site-packages\n",
      "Editable project location: /work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm\n",
      "Requires: accelerate, appdirs, bitsandbytes, black, black, datasets, fire, hydra-core, loralib, optimum, peft, py7zr, scipy, sentencepiece, torch, transformers, wandb\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show slam-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d12d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Submitted batch job 43245575']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!sbatch strain.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d30d58-a2ee-4fc3-bdab-afdbcc46ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          43245575       gpu strain.b zhang.ji  R       0:18      1 d1028\n",
      "          43243947       gpu sys/dash zhang.ji  R    3:42:28      1 d1022\n",
      "          43236898     short sys/dash zhang.ji  R   12:20:00      1 c0166\n"
     ]
    }
   ],
   "source": [
    "!squeue -u zhang.jinda1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b766e-c1e6-4c3e-8079-27d17738f9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
